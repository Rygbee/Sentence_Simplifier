
   
   
                               Clause Splitting
                                       
   Clauses are word sequences which contain a subject and a predicate.
   Here is an example of a sentence and its clauses obtained from Wall
   Street Journal section 15 of the Penn Treebank [MSM93]:
   
   (S The deregulation of railroads and trucking companies
      (SBAR that
          (S began in 1980)
      )
      enabled
      (S shippers to bargain for transportation)
      .
   )

   The clauses of this sentence have been enclosed between brackets. A
   tag next to the open bracket denotes the type of the clause.
   
   In the CoNLL-2001 shared task, the goal is to identify clauses in
   text. Training and test data for this task are available. This data
   consists of the same partitions of the Wall Street Journal part (WSJ)
   of the Penn Treebank as the widely used data for noun phrase chunking:
   sections 15-18 as training data (211727 tokens) and section 20 as test
   data (47377 tokens). The clause segmentation of the data has been
   derived from the Penn Treebank by a program written by Sabine Buchholz
   from Tilburg University, The Netherlands.
   
   The shared task consists of three parts: identifying clause start
   positions, recognizing clause end positions and building complete
   clauses. We have not used clauses labeled with FRAG or RRC, and all
   clause labels have been converted to S. The goal of this task is to
   come forward with machine learning methods which after a training
   phase can recognize the clause segmentation of the test data as well
   as possible. For all three parts of the shared task, the clause
   segmentation methods will be evaluated with the F rate, which is a
   combination of the precision and recall rates: F = 2*precision*recall
   / (recall+precision) [Rij79].
   
Background Information

   There have been some earlier studies in identifying clauses. [Abn90]
   used a clause filter as a part of his CASS parser. It consists of two
   parts: one for recognizing basic clauses and one for repairing
   difficult cases (clauses without subjects and clauses with additional
   VPs). [Eje96] showed that a parser can benefit from automatically
   identified clause boundaries in discourse. [Lef98] built a rule-based
   algorithm for finding clauses in English and Portuguese texts. [Ora00]
   used memory-based learning techniques for finding clauses in the
   Susanne corpus. His system included a rule-based post-processing phase
   for improving clause recognition performance.
   
Software and Data

   The train and test data consist of four columns separated by spaces.
   Each word has been put on a separate line and there is an empty line
   after each sentence. The first column contains the current word, the
   second a part-of-speech tag derived by the Brill tagger, the third a
   chunk tag generated by a chunker [TKS00] and the fourth a
   corresponding clause tag extracted from the Penn Treebank. The chunk
   tags contain two parts: one stating whether the word is chunk initial
   (B) or not (I), and one holding the type of the chunk (NP, VP, PP,
   etcetera). There are two varieties of chunk tags: one for start/end
   parts which uses S (start), E (end) and X (neither), and one for the
   complete clause segmentation which contains (S* (start), *S) (end), *
   (neither) and several combinations such as (S(S*S) (two clause starts
   and one clause end). Here is an example:
   
              The   DT   B-NP  S/X/(S*
     deregulation   NN   I-NP  X/X/*
               of   IN   B-PP  X/X/*
        railroads  NNS   B-NP  X/X/*
              and   CC      O  X/X/*
         trucking   NN   B-NP  X/X/*
        companies  NNS   I-NP  X/X/*
             that  WDT   B-NP  S/X/(S*
            began  VBD   B-VP  S/X/(S*
               in   IN   B-PP  X/X/*
             1980   CD   B-NP  X/E/*S)S)
          enabled  VBD   B-VP  X/X/*
         shippers  NNS   B-NP  S/X/(S*
               to   TO   B-VP  X/X/*
          bargain   VB   I-VP  X/X/*
              for   IN   B-PP  X/X/*
   transportation   NN   B-NP  X/E/*S)
                .    .      O  X/E/*S)

   In this example, the fourth column contains the clause tags for part
   1, 2 and 3 of the shared task separated by slashes. In the third
   column, the O chunk tag is used for tokens which are not part of any
   chunk.
   
   There are two evaluation programs (Perl) available: one for parts 1
   and 2 (conlleval1) and one for part 3 (conlleval3). The input of the
   programs should consist of a file which is the same as the test data
   but which contains an additional final column which holds the results
   of that should be evaluated. The programs should be invoked as
   conlleval1 < file
   
     * [1]http://lcg-www.uia.ac.be/conll2001/clauses/clauses.tgz
       The data sets and evaluation software for this shared task in one
       gzipped tar file. You can also retrieve these files one by one:
       [2]data and [3]software. The first two columns in the data files
       have been extracted from the [RM95] NP chunking data which is
       available from: [4]ftp://ftp.cis.upenn.edu/pub/chunker/
     * [5]http://ilk.kub.nl/~sabine/chunklink/
       The Perl script that was used for generating these training and
       test data sets from the Penn Treebank. It has been written by
       Sabine Buchholz from Tilburg University.
       
Results

   In order to obtain baseline performances for the different parts of
   the task, we applied a simple clause segmentation system to the test
   data sets. This system assumes that every sentence contains one clause
   which completely contains the sentence. The performance of this system
   can be found in the next table:
   
              +-----------+-----------++-----------++
     baseline | precision |   recall  ||     F     ||
   +----------+-----------+-----------++-----------++
   | part 1   |   96.32%  |   38.08%  ||   54.58   ||
   +----------+-----------+-----------++-----------++
   | part 2   |   96.32%  |   51.86%  ||   67.42   ||
   +----------+-----------+-----------++-----------++
   | part 3   |   96.32%  |   35.77%  ||   52.17   ||
   +----------+-----------+-----------++-----------++

   Other systems which are applied to parts of the shared task should at
   least improve the relevant baseline scores.
   
Submission guidelines

   Send an abstract of no more than 1500 words describing the learning
   approach used (preferably in plain ASCII) together with your results
   on the test set to erikt@uia.ua.ac.be (Erik Tjong Kim Sang) by April
   6, 2001. The authors of accepted papers will be asked to apply their
   system to an extra test set which will be made available after the
   notification date (April 27).
   
Related information

     * [6]http://lcg-www.uia.ac.be/conll2001/
       Home page of the workshop on Computational Natural Language
       Learning (CoNLL-2001)
       
References

     * [Abn90]
       Steven Abney, Rapid Incremental Parsing with Repair. In
       "Proceedings of the 8th New OED Conference: Electronic Text
       Research", University of Waterloo, Ontario, 1990.
       [7]http://whorf.sfs.nphil.uni-tuebingen.de/~abney/90j.ps.gz
     * [Bri94]
       Eric Brill, Some Advances in Rule-Based Part of Speech Tagging. In
       "Proceedings of the Twelfth National Conference on Artificial
       Intelligence (AAAI-94)", Seattle, Washington, 1994.
       [8]ftp://ftp.cs.columbia.edu/pub/cs4999/brill94.ps
     * [DT01]
       Hervé Déjean and Erik F. Tjong Kim Sang, Introduction to the
       CoNLL-2001 Shared Task: Clause Identification. To appear in
       "Proceedings of CoNLL-2001", 2001.
       [9]http://lcg-www.uia.ac.be/conll2001/clauses/intro.ps
     * [Eje96]
       Eva Ejerhed, Finite State Segmentation of Discourse into Clauses.
       In "Proceedings of the ECAI '96 Workshop on Extended finite state
       models of language", ECAI '96, Budapest, Hungary, 1996.
       [10]http://www.kornai.com/ECAI/ejerhed.ps.gz
     * [Lef98]
       Vilson J. Leffa, Clause processing in complex sentences. In:
       "Proceedings of LREC'98", Granada, Espanha, 1998.
       [11]http://atlas.ucpel.tche.br/~leffa/granada.pdf
     * [MSM93]
       Mitchell P. Marcus, Beatrice Santorini and Mary Ann Marcinkiewicz,
       Building a large annotated corpus of English: the Penn Treebank,
       In: "Computational Linguistics", 19:2, 1993.
       [12]http://morph.ldc.upenn.edu/Catalog/docs/treebank2/cl93.html
       (paper)
       [13]http://morph.ldc.upenn.edu/Catalog/LDC95T7.html (corpus
       information)
     * [Ora00]
       Constantin Orasan, A hybrid method for clause splitting in
       unrestricted English texts, In: "Proceedings of ACIDCA'2000",
       Monastir, Tunisia, 2000.
       [14]http://www.wlv.ac.uk/sles/compling/papers/orasan-00.pdf
     * [RM95]
       Lance A. Ramshaw and Mitchell P. Marcus, Text Chunking Using
       Transformation-Based Learning. In: "Proceedings of the Third ACL
       Workshop on Very Large Corpora", Association for Computational
       Linguistics, 1995.
       [15]ftp://ftp.cis.upenn.edu/pub/chunker/wvlcbook.ps.gz
     * [Rij79]
       C.J. van Rijsbergen, "Information Retrieval". Buttersworth, 1979.
     * [TKS00]
       Erik F. Tjong Kim Sang. Text Chunking by System Combination. In
       "Proceedings of CoNLL-2000 and LLL-2000", Lisbon, Portugal, 2000.
       [16]http://lcg-www.uia.ac.be/conll2000/ps/15153tjo.ps
     _________________________________________________________________
   
   
    Last update: March 26, 2001. [17]erikt@uia.ua.ac.be

References

   1. http://lcg-www.uia.ac.be/conll2001/clauses/clauses.tgz
   2. file://localhost/export/home/staff/web/pub/conll2001/clauses/data/
   3. file://localhost/export/home/staff/web/pub/conll2001/clauses/bin/
   4. ftp://ftp.cis.upenn.edu/pub/chunker/
   5. http://ilk.kub.nl/~sabine/chunklink/
   6. http://lcg-www.uia.ac.be/conll2001/
   7. http://whorf.sfs.nphil.uni-tuebingen.de/~abney/90j.ps.gz
   8. ftp://ftp.cs.columbia.edu/pub/cs4999/brill94.ps
   9. http://lcg-www.uia.ac.be/conll2001/clauses/intro.ps
  10. http://www.kornai.com/ECAI/ejerhed.ps.gz
  11. http://atlas.ucpel.tche.br/~leffa/granada.pdf
  12. http://morph.ldc.upenn.edu/Catalog/docs/treebank2/cl93.html
  13. http://morph.ldc.upenn.edu/Catalog/LDC95T7.html
  14. http://www.wlv.ac.uk/sles/compling/papers/orasan-00.pdf
  15. ftp://ftp.cis.upenn.edu/pub/chunker/wvlcbook.ps.gz
  16. http://lcg-www.uia.ac.be/conll2000/ps/15153tjo.ps
  17. mailto:erikt@uia.ua.ac.be
